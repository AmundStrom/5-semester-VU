{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge and Data: Practical Assignment 3 \n",
    "## RDF Data, RDFS knowledge and inferencing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR NAME: Amund Strøm\n",
    "\n",
    "YOUR VUNetID: ast101\n",
    "\n",
    "*(If you do not provide your name and VUNetID we will not accept your submission).* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "\n",
    "At the end of this exercise you should be able to:\n",
    "\n",
    "1. Access local an external data via SPARQL both from within a python programming environment and stand-alone with a GUI, such as [YASGUI](https://yasgui.triply.cc/), and this way integrate data from different sources  \n",
    "2. Model your own first knowledge base, in this case an RDF Schema knowledge graph\n",
    "3. Implement inference rules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow this Notebook step-by-step. \n",
    "\n",
    "Of course, you can do the exercises in any Programming Editor of your liking. \n",
    "But you do not have to. Feel free to simply write code in the Notebook. When \n",
    "everythink is filled in and works, safe the Notebook and submit it \n",
    "as a Jupyter Notebook, i.e. with an ipynb extension. Please use as name of the \n",
    "Notebook your studentID+Assignment3.ipynb.  \n",
    "\n",
    "\n",
    "We will not evaluate the programming style of your solutions. Yet we do look whether your solutions suggests an understanding, and whether they yield the correct output.\n",
    "\n",
    "Note that all notebooks will automatically be checked for plagiarism: while similar answers can be expected, it is not allowed to directly copy the solutions from fellow students or TAs, or from the examples discussed during the lectures. Similarly, sharing your solutions with your peers is not allowed.\n",
    "\n",
    "**IMPORTANT: Submit this notebook after finishing the assignment. It is not necessary to submit the created turtle files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you start, you need to:\n",
    "\n",
    "- **Install the *rdflib* Python package:** *pip install rdflib* (should already be installed from the previous assignment)\n",
    "- **Install the *SPARQLWrapper* Python package:** *pip install SPARQLWrapper*\n",
    "- **Install the free edition of the GraphDB Triplestore:** please follow this short [GraphDB tutorial](https://github.com/ucds-vu/knowledge-data-vu/blob/master/Tutorials/Preliminaries/tutorial-GraphDB.md). \n",
    "\n",
    "Then, add the file example-from-slides.ttl to a newly created database, say called assignment-3. \n",
    "\n",
    "**Note that you should have an active internet connection to run the code in this notebook. Also, if, for some external reason (ie internet and/or system issues), you cannot access the SPARQL endpoint, then report this to a TA as soon as possible!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SPARQLWrapper in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.0.0)\n",
      "Requirement already satisfied: rdflib>=6.1.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from SPARQLWrapper) (7.0.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rdflib>=6.1.1->SPARQLWrapper) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.1.1)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->SPARQLWrapper) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install library\n",
    "%pip install SPARQLWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: (35 points) Integrate Local and External Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can integrate SPARQL queries into your Python code by using the *RDFLib* and *SPARQLWrapper* libraries. \n",
    "\n",
    "The following code accesses the DBPedia knowledge graph using its SPARQL endpoint, and returns the result of the SPARQL query requesting all the labels asserted to Amsterdam (test it!)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amsterdam\n",
      "أمستردام\n",
      "Amsterdam\n",
      "Amsterdam\n",
      "Amsterdam\n",
      "Άμστερνταμ\n",
      "Amsterdamo\n",
      "Ámsterdam\n",
      "Amsterdam\n",
      "Amstardam\n",
      "Amsterdam\n",
      "Amsterdam\n",
      "Amsterdam\n",
      "암스테르담\n",
      "アムステルダム\n",
      "Amsterdam\n",
      "Amsterdam\n",
      "Амстердам\n",
      "Amesterdão\n",
      "Amsterdam\n",
      "Амстердам\n",
      "阿姆斯特丹\n"
     ]
    }
   ],
   "source": [
    "# This code only works if you are online.\n",
    "# If, for some reason, you cannot get this to work, then please contact a TA\n",
    "\n",
    "from rdflib import Graph, RDF, RDFS, Namespace, Literal, URIRef\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT ?cityName\n",
    "    WHERE { \n",
    "        <http://dbpedia.org/resource/Amsterdam> rdfs:label ?cityName\n",
    "    }\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result[\"cityName\"][\"value\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your convenience, we already wrote the following functions that might be useful to complete this task. \n",
    "In addition, we have loaded and printed the 'example-from-slides.ttl' dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ex: <http://example.com/kad/> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "\n",
      "ex:Netherlands a ex:Country ;\n",
      "    ex:contains ex:Ijsselmeer ;\n",
      "    ex:containsCity ex:Rotterdam ;\n",
      "    ex:hasCapital ex:Amsterdam ;\n",
      "    ex:hasName \"The Netherlands\" ;\n",
      "    ex:neighbours ex:Belgium .\n",
      "\n",
      "ex:hasCapital rdfs:range ex:Capital ;\n",
      "    rdfs:subPropertyOf ex:containsCity .\n",
      "\n",
      "ex:neighbours rdfs:subPropertyOf ex:closeBy .\n",
      "\n",
      "ex:Amsterdam a ex:Capital ;\n",
      "    ex:closeBy ex:Germany .\n",
      "\n",
      "ex:Belgium a ex:Country .\n",
      "\n",
      "ex:EuropeanCountry rdfs:subClassOf ex:Country .\n",
      "\n",
      "ex:Germany a ex:EuropeanCountry ;\n",
      "    ex:hasCapital ex:Berlin .\n",
      "\n",
      "ex:closeBy rdfs:domain ex:Location ;\n",
      "    rdfs:range ex:Location .\n",
      "\n",
      "ex:containsCity rdfs:domain ex:Country ;\n",
      "    rdfs:range ex:City ;\n",
      "    rdfs:subPropertyOf ex:contains .\n",
      "\n",
      "ex:Capital rdfs:subClassOf ex:City .\n",
      "\n",
      "ex:City rdfs:subClassOf ex:Location .\n",
      "\n",
      "ex:Country rdfs:subClassOf ex:Location .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, RDF, Namespace, Literal, URIRef\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "\n",
    "# Loads the data from a certain file given as input in Turtle syntax into the Graph g  \n",
    "# -------------------------\n",
    "def load_graph(graph, filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        graph.parse(f, format='turtle')\n",
    "        \n",
    "\n",
    "# Prints a certain graph given as input in Turtle syntax\n",
    "# if your output shows byte string (ie, b'...') you must add '.decode()' to the print statements:\n",
    "#    print(myGraph.serialize(format='turtle').decode())\n",
    "# -------------------------\n",
    "def serialize_graph(myGraph):\n",
    "     print(myGraph.serialize(format='turtle'))\n",
    "        \n",
    "\n",
    "# Saves the Graph g in Turtle syntax to a certain file given as input\n",
    "# -------------------------\n",
    "def save_graph(myGraph, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        myGraph.serialize(filename, format='turtle')\n",
    "        \n",
    "    \n",
    "# Changes the namespace of a certain URI given as input to a DBpedia URI \n",
    "# Example: transformToDBR(\"http://example.com/kad2020/Amsterdam\") returns \"http://dbpedia.org/resource/Amsterdam\"\n",
    "# -------------------------\n",
    "def transformToDBR(uri):\n",
    "    if isinstance(uri, Literal):\n",
    "        # changes the literal to uppercase so that the object with the same name refers to an object and not the string\n",
    "        return uri.upper()\n",
    "    components = g.namespace_manager.compute_qname(uri)\n",
    "    return \"http://dbpedia.org/resource/%s\"%(components[2])\n",
    "\n",
    "# -------------------------\n",
    "\n",
    "g = Graph()\n",
    "load_graph(g, 'example-from-slides.ttl')\n",
    "serialize_graph(g)\n",
    "\n",
    "\n",
    "# Don't forget to run this cell before continuing the task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: Write a SPARQL query that finds all the cities in the dataset\n",
    "\n",
    "As you cannot directly use class City, you will have to find those cities in the dataset (example-from-slides.ttl) using implicit information that can be deduced from the domain and ranges of the relations (e.g. things in a hasCapital relation are capitals and a capital is a city, etc.).\n",
    "\n",
    "Save all the cities returned from the SPARQL query into the empty set \"cities\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/kad/Rotterdam\n",
      "http://example.com/kad/Amsterdam\n",
      "http://example.com/kad/Berlin\n"
     ]
    }
   ],
   "source": [
    "cities = set()\n",
    "\n",
    "cities = g.query(\n",
    "    \"\"\"\n",
    "    PREFIX ex: <http://example.com/kad/>\n",
    "\n",
    "    SELECT ?city\n",
    "    WHERE {\n",
    "        {?s ex:containsCity ?city}\n",
    "        UNION \n",
    "        {?s ex:hasCapital ?city}\n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "    \n",
    "for city in cities:\n",
    "    print(city[0]) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: For each city, find from DBpedia its longitude & latitude, and its number of inhabitants (if available)\n",
    "\n",
    "Don't forget to adapt the namespace of the cities in your dataset when querying DBpedia, using the above function *transformToDBR(uri)*. Also note that namespaces should never use the *https* protocol.\n",
    "\n",
    "The empty graph h should only contain the triples extracted from DBpedia, but added to the URIs with the 'ex' namespace. \n",
    "An example of a triple in h is the following triple: \n",
    "       \n",
    "       ex:Amsterdam dbo:populationTotal \"872680\"^^xsd:nonNegativeInteger ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'http://www.example.org/pizza' should become 'pizza'\n",
    "\n",
    "def clear(e, char=\"/\"):\n",
    "    striped = e.split(char)\n",
    "    return(striped[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix dbo: <http://dbpedia.org/ontology/> .\n",
      "@prefix ex: <http://example.com/kad/> .\n",
      "@prefix geo1: <http://www.w3.org/2003/01/geo/wgs84_pos#> .\n",
      "\n",
      "ex:Amsterdam dbo:populationTotal \"907976\" ;\n",
      "    geo1:lat \"52.3667\" ;\n",
      "    geo1:long \"4.9\" .\n",
      "\n",
      "ex:Berlin dbo:populationTotal \"3677472\" ;\n",
      "    geo1:lat \"52.52\" ;\n",
      "    geo1:long \"13.405\" .\n",
      "\n",
      "ex:Rotterdam dbo:populationTotal \"651157\" ;\n",
      "    geo1:lat \"51.9167\" ;\n",
      "    geo1:long \"4.5\" .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define namespaces\n",
    "geo = Namespace(\"http://www.w3.org/2003/01/geo/wgs84_pos#\")\n",
    "dbo = Namespace(\"http://dbpedia.org/ontology/\")\n",
    "ex = Namespace(\"http://example.com/kad/\")\n",
    "\n",
    "# Create empty graph\n",
    "h = Graph()\n",
    "\n",
    "# Bind namespaces to a prefix\n",
    "h.bind(\"geo\", geo)\n",
    "h.bind(\"dbo\", dbo)\n",
    "h.bind(\"ex\", ex)\n",
    "\n",
    "# Loop through every city\n",
    "for city in cities:\n",
    "    # Adapt the namespace for the city\n",
    "    dbp = transformToDBR(city[0]).strip()\n",
    "    \n",
    "    # Query\n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "    sparql.setQuery(\n",
    "        \"\"\"\n",
    "        PREFIX geo: <http://www.w3.org/2003/01/geo/wgs84_pos#>\n",
    "        PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\n",
    "        SELECT ?population ?long ?lat\n",
    "        WHERE {\n",
    "            { <\"\"\"+ dbp +\"\"\"> dbo:populationTotal ?population . }\n",
    "            { <\"\"\"+ dbp +\"\"\"> geo:long ?long . }\n",
    "            { <\"\"\"+ dbp +\"\"\"> geo:lat ?lat . }\n",
    "        }\n",
    "\n",
    "        \"\"\"\n",
    "    )\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    # Add result from query into graph\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        h.add((ex[clear(dbp)], dbo.populationTotal, Literal(result[\"population\"][\"value\"])))\n",
    "        h.add((ex[clear(dbp)], geo.long, Literal(result[\"long\"][\"value\"])))\n",
    "        h.add((ex[clear(dbp)], geo.lat, Literal(result[\"lat\"][\"value\"])))\n",
    "\n",
    "\n",
    "serialize_graph(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C: Save your results\n",
    "\n",
    "- Merge the triples from example-from-slides.ttl with the information extracted from DBpedia. See the [documentation](https://rdflib.readthedocs.io/en/stable/merging.html) on how to accomplish this.\n",
    "- Save all these triples into a new file 'extended-example.ttl'. **It is not necessary to submit this file**\n",
    "- Print all triples in Turtle Syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix dbo: <http://dbpedia.org/ontology/> .\n",
      "@prefix ex: <http://example.com/kad/> .\n",
      "@prefix geo1: <http://www.w3.org/2003/01/geo/wgs84_pos#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "\n",
      "ex:Netherlands a ex:Country ;\n",
      "    ex:contains ex:Ijsselmeer ;\n",
      "    ex:containsCity ex:Rotterdam ;\n",
      "    ex:hasCapital ex:Amsterdam ;\n",
      "    ex:hasName \"The Netherlands\" ;\n",
      "    ex:neighbours ex:Belgium .\n",
      "\n",
      "ex:hasCapital rdfs:range ex:Capital ;\n",
      "    rdfs:subPropertyOf ex:containsCity .\n",
      "\n",
      "ex:neighbours rdfs:subPropertyOf ex:closeBy .\n",
      "\n",
      "ex:Amsterdam a ex:Capital ;\n",
      "    dbo:populationTotal \"907976\" ;\n",
      "    ex:closeBy ex:Germany ;\n",
      "    geo1:lat \"52.3667\" ;\n",
      "    geo1:long \"4.9\" .\n",
      "\n",
      "ex:Belgium a ex:Country .\n",
      "\n",
      "ex:Berlin dbo:populationTotal \"3677472\" ;\n",
      "    geo1:lat \"52.52\" ;\n",
      "    geo1:long \"13.405\" .\n",
      "\n",
      "ex:EuropeanCountry rdfs:subClassOf ex:Country .\n",
      "\n",
      "ex:Germany a ex:EuropeanCountry ;\n",
      "    ex:hasCapital ex:Berlin .\n",
      "\n",
      "ex:Rotterdam dbo:populationTotal \"651157\" ;\n",
      "    geo1:lat \"51.9167\" ;\n",
      "    geo1:long \"4.5\" .\n",
      "\n",
      "ex:closeBy rdfs:domain ex:Location ;\n",
      "    rdfs:range ex:Location .\n",
      "\n",
      "ex:containsCity rdfs:domain ex:Country ;\n",
      "    rdfs:range ex:City ;\n",
      "    rdfs:subPropertyOf ex:contains .\n",
      "\n",
      "ex:Capital rdfs:subClassOf ex:City .\n",
      "\n",
      "ex:City rdfs:subClassOf ex:Location .\n",
      "\n",
      "ex:Country rdfs:subClassOf ex:Location .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "mergedGraph = Graph()\n",
    "\n",
    "mergedGraph= g + h\n",
    "\n",
    "save_graph(mergedGraph, 'extended-example.ttl')\n",
    "serialize_graph(mergedGraph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: (25 points)  Implement Basic Inferencing Rules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture we showed that the RDFS inference rules can be used to infer new knowledge. For example, infer class membership based on _rdfs:domain_ or infer relationships between subjects and objects based on _rdfs:subPropertyOf_. \n",
    "\n",
    "Create rules to inference class membership based on the RDF Schema language features \n",
    "*\tFor example: infer that an instance belongs to a class because of domain and range restrictions\n",
    "*\tFor example: infer that an instance belongs to a (super)class because it also belongs to a subclass\n",
    "\n",
    "We implemented the __rdfs2__ rule. You should implement the 5 following remaining rules:  \n",
    "\n",
    "*     (rdfs2) If G contains the triples (aaa rdfs:domain xxx.) and (uuu aaa yyy.)  then infer the triple (uuu rdf:type xxx.)\n",
    "*     (rdfs3) If G contains the triples (aaa rdfs:range xxx.) and (uuu aaa vvv.) then infer the triple (vvv rdf:type xxx .)\n",
    "*     (rdfs5) If G contains the triples (uuu rdfs:subPropertyOf vvv.) and (vvv rdfs:subPropertyOf xxx.) then infer the triple\n",
    "(uuu rdfs:subPropertyOf xxx.) \n",
    "*     (rdfs7) If G contains the triples (aaa rdfs:subPropertyOf bbb.) and (uuu aaa yyy.) then infer the triple (uuu bbb yyy) \n",
    "*     (rdfs9) If G contains the triples (uuu rdfs:subClassOf xxx.) and (vvv rdf:type uuu.) then infer the triple\n",
    " (vvv rdf:type xxx.)   -> this one was not mentioned in the lecture, but is a very important one. \n",
    "*     (rdfs11) If G contains the triples (uuu rdfs:subClassOf vvv.) and (vvv rdfs:subClassOf xxx.) then infer the triple\n",
    "(uuu rdfs:subClassOf xxx.)\n",
    "\n",
    "\n",
    "Run your rule reasoner on your knowledge graph. If you have implemented everything correctly, you should find exactly 17 inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(rdfs 7)  http://example.com/kad/Netherlands closeBy http://example.com/kad/Belgium\n",
      "(rdfs 3)  http://example.com/kad/Germany rdf:type http://example.com/kad/Location\n",
      "(rdfs 9)  http://example.com/kad/Netherlands rdf:type http://example.com/kad/Location\n",
      "(rdfs 9)  http://example.com/kad/Belgium rdf:type http://example.com/kad/Location\n",
      "(rdfs 2)  http://example.com/kad/Netherlands rdf:type http://example.com/kad/Country\n",
      "(rdfs 5)  http://example.com/kad/hasCapital rdf:subPropertyOf http://example.com/kad/contains\n",
      "(rdfs 7)  http://example.com/kad/Netherlands containsCity http://example.com/kad/Amsterdam\n",
      "(rdfs 7)  http://example.com/kad/Germany containsCity http://example.com/kad/Berlin\n",
      "(rdfs 3)  http://example.com/kad/Amsterdam rdf:type http://example.com/kad/Capital\n",
      "(rdfs 3)  http://example.com/kad/Berlin rdf:type http://example.com/kad/Capital\n",
      "(rdfs 3)  http://example.com/kad/Rotterdam rdf:type http://example.com/kad/City\n",
      "(rdfs 9)  http://example.com/kad/Germany rdf:type http://example.com/kad/Country\n",
      "(rdfs 11)  http://example.com/kad/Germany rdf:subClassOf http://example.com/kad/Location\n",
      "(rdfs 9)  http://example.com/kad/Amsterdam rdf:type http://example.com/kad/City\n",
      "(rdfs 11)  http://example.com/kad/hasCapital rdf:subClassOf http://example.com/kad/Location\n",
      "(rdfs 2)  http://example.com/kad/Amsterdam rdf:type http://example.com/kad/Location\n",
      "(rdfs 7)  http://example.com/kad/Netherlands contains http://example.com/kad/Rotterdam\n",
      "---------------------------------\n",
      "Number of inferred triples: 17\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "def myRDFSreasoner(myGraph):\n",
    "    inferredTriples = 0\n",
    "    for sbj, prd, obj in myGraph:\n",
    "\n",
    "        # --- rdfs2 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#domain\"))):\n",
    "            generator = myGraph.subject_objects(URIRef(sbj))\n",
    "            for s, o in generator:\n",
    "                inferredTriples += 1\n",
    "                print(\"(rdfs 2) \", s, \"rdf:type\", obj)\n",
    "        \n",
    "        # --- rdfs3 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#range\"))):\n",
    "            generator = myGraph.subject_objects(URIRef(sbj))\n",
    "            for s, o in generator:\n",
    "                inferredTriples += 1\n",
    "                print(\"(rdfs 3) \", o, \"rdf:type\", obj)\n",
    "        \n",
    "        # --- rdfs5 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#subPropertyOf\"))):\n",
    "            generator = myGraph.predicate_objects(URIRef(obj))\n",
    "            for p, o in generator:\n",
    "                if (p.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#subPropertyOf\"))):\n",
    "                    inferredTriples += 1\n",
    "                    print(\"(rdfs 5) \", sbj, \"rdf:subPropertyOf\", o)\n",
    "        \n",
    "        # --- rdfs7 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#subPropertyOf\"))):\n",
    "            generator = myGraph.subject_objects(URIRef(sbj))\n",
    "            for s, o in generator:\n",
    "                inferredTriples += 1\n",
    "                print(\"(rdfs 7) \", s, clear(obj), o)\n",
    "        \n",
    "        # --- rdfs9 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#subClassOf\"))):\n",
    "            generator = myGraph.subject_predicates(URIRef(sbj))\n",
    "            for s, p in generator:\n",
    "                if (p.eq(URIRef(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\"))):\n",
    "                    inferredTriples += 1\n",
    "                    print(\"(rdfs 9) \", s, \"rdf:type\", obj)\n",
    "        \n",
    "        # --- rdfs11 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#subClassOf\"))):\n",
    "            generator = myGraph.predicate_objects(URIRef(obj))\n",
    "            for p, o in generator:\n",
    "                if (p.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#subClassOf\"))):\n",
    "                    inferredTriples += 1\n",
    "                    print(\"(rdfs 11) \", s, \"rdf:subClassOf\", o)\n",
    "\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Number of inferred triples:\", inferredTriples)\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "myRDFSreasoner(g)  # test your reasoner\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: (20 points) Build your very own RDFS knowledge graph. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a small RDF Schema vocabulary in Turtle. You can choose your own domain (e.g. movies, geography, sports), as long as it hasn't been used as an example during the lectures. The following rules must be respected:\n",
    "*\tThe schema should define at least 4 classes, 4 properties, and 4 instances.\n",
    "*   The properties should be used to relate the instances (i.e., object-type relations)\n",
    "*\tThe instances should be members of at least one of the 4 defined classes\n",
    "*\tAll resources should have an rdfs:label attribute in a suitable language.\n",
    "\n",
    "You should use (at least) the following language features of RDF and RDFS:\n",
    "* \trdf:type (or 'a')\n",
    "* \trdfs:subClassOf\n",
    "* \trdfs:subPropertyOf\n",
    "* \trdfs:domain and rdfs:range\n",
    "*\trdfs:label\n",
    "\n",
    "Be sure to define the 'rdf:' and 'rdfs:' namespace prefixes for RDF and RDF Schema in your file (perhaps have a look at http://prefix.cc)\n",
    "\n",
    "For creating your vocabulary you should add the axioms directly (programatically) to your Knowledge Graph as you did last week. \n",
    "\n",
    "Play around with the inference rules you have created in the previous task to make sure that you added some implicit knowledge, that becomes \"visible\" via inferencing (this will be useful for the next task). \n",
    "\n",
    "Finally:\n",
    "- Add the knowledge you created into the RDFlib graph datastructure *myRDFSgraph*, \n",
    "- Print *myRDFSgraph* in Turtle so that we can check your \"design\"\n",
    "- Save *myRDFSgraph* into a new file 'myRDFSgraph.ttl' (it is not necessary to submit this file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now let's check what we can infer from your knowledge graph...\n",
      "The more rules you cover, the better!\n",
      "(rdfs 2)  http://example.com/kad/LoL rdf:type http://example.com/kad/Videogame\n",
      "(rdfs 2)  http://example.com/kad/Convergence rdf:type http://example.com/kad/Videogame\n",
      "(rdfs 11)  http://example.com/kad/Convergence rdf:subClassOf http://example.com/kad/Computer\n",
      "(rdfs 3)  http://example.com/kad/MOBA rdf:type http://example.com/kad/Genre\n",
      "(rdfs 3)  http://example.com/kad/Platformer rdf:type http://example.com/kad/Genre\n",
      "(rdfs 9)  http://example.com/kad/LoL rdf:type http://example.com/kad/Computer\n",
      "(rdfs 5)  http://example.com/kad/RiotClient rdf:subPropertyOf http://example.com/kad/Computer\n",
      "(rdfs 3)  http://example.com/kad/RiotClient rdf:type http://example.com/kad/Platform\n",
      "(rdfs 7)  http://example.com/kad/LoL rdf-schema#Literal Leauge of Legends\n",
      "(rdfs 7)  http://example.com/kad/Convergence rdf-schema#Literal CONVERGENCE: a League of Legends Story\n",
      "(rdfs 2)  http://example.com/kad/Riot rdf:type http://example.com/kad/Publisher\n",
      "(rdfs 3)  http://example.com/kad/Riot rdf:type http://example.com/kad/Publisher\n",
      "(rdfs 3)  http://example.com/kad/Riot rdf:type http://example.com/kad/Publisher\n",
      "---------------------------------\n",
      "Number of inferred triples: 13\n",
      "---------------------------------\n",
      "@prefix ex: <http://example.com/kad/> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "\n",
      "ex:Convergence ex:hasGenre ex:Platformer ;\n",
      "    ex:hasTitle \"CONVERGENCE: a League of Legends Story\" ;\n",
      "    ex:publishedBy ex:Riot ;\n",
      "    rdfs:subClassOf ex:VideoGame .\n",
      "\n",
      "ex:LoL a ex:VideoGame ;\n",
      "    ex:availableOn ex:RiotClient ;\n",
      "    ex:hasGenre ex:MOBA ;\n",
      "    ex:hasTitle \"Leauge of Legends\" ;\n",
      "    ex:publishedBy ex:Riot .\n",
      "\n",
      "ex:availableOn rdfs:range ex:Platform .\n",
      "\n",
      "ex:founded rdfs:domain ex:Publisher .\n",
      "\n",
      "ex:hasGenre rdfs:range ex:Genre .\n",
      "\n",
      "ex:hasTitle rdfs:domain ex:Videogame ;\n",
      "    rdfs:subPropertyOf rdfs:Literal .\n",
      "\n",
      "ex:publishedBy rdfs:range ex:Publisher .\n",
      "\n",
      "ex:RiotClient rdfs:subPropertyOf ex:Platform .\n",
      "\n",
      "ex:Platform rdfs:subPropertyOf ex:Computer .\n",
      "\n",
      "ex:Riot a ex:Publisher ;\n",
      "    rdfs:label \"Riot Games\" ;\n",
      "    ex:founded \"2006\" .\n",
      "\n",
      "ex:VideoGame rdfs:subClassOf ex:Computer .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define namespaces\n",
    "ex = Namespace(\"http://example.com/kad/\")\n",
    "rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "\n",
    "# Create graph\n",
    "myRDFSgraph = Graph()\n",
    "\n",
    "# Bind namespaces to prefixes\n",
    "myRDFSgraph.bind(\"ex\", ex)\n",
    "myRDFSgraph.bind(\"rdf\", rdf)\n",
    "myRDFSgraph.bind(\"rdfs\", rdfs)\n",
    "\n",
    "\n",
    "myRDFSgraph.add((ex.LoL, RDF.type, ex.VideoGame))\n",
    "myRDFSgraph.add((ex.LoL, ex.hasTitle, Literal(\"Leauge of Legends\")))\n",
    "myRDFSgraph.add((ex.LoL, ex.hasGenre, ex.MOBA))\n",
    "myRDFSgraph.add((ex.LoL, ex.publishedBy, ex.Riot))\n",
    "myRDFSgraph.add((ex.LoL, ex.availableOn, ex.RiotClient))\n",
    "\n",
    "myRDFSgraph.add((ex.Riot, RDF.type, ex.Publisher))\n",
    "myRDFSgraph.add((ex.Riot, ex.founded, Literal(\"2006\")))\n",
    "myRDFSgraph.add((ex.Riot, rdfs.label, Literal(\"Riot Games\")))\n",
    "\n",
    "myRDFSgraph.add((ex.Convergence, rdfs.subClassOf, ex.VideoGame))\n",
    "myRDFSgraph.add((ex.Convergence, ex.hasTitle, Literal(\"CONVERGENCE: a League of Legends Story\")))\n",
    "myRDFSgraph.add((ex.Convergence, ex.hasGenre, ex.Platformer))\n",
    "myRDFSgraph.add((ex.Convergence, ex.publishedBy, ex.Riot))\n",
    "\n",
    "myRDFSgraph.add((ex.RiotClient, rdfs.subPropertyOf, ex.Platform))\n",
    "myRDFSgraph.add((ex.Platform, rdfs.subPropertyOf, ex.Computer))\n",
    "myRDFSgraph.add((ex.VideoGame, rdfs.subClassOf, ex.Computer))\n",
    "\n",
    "myRDFSgraph.add((ex.founded, rdfs.domain, ex.Publisher))\n",
    "myRDFSgraph.add((ex.hasGenre, rdfs.range, ex.Genre))\n",
    "myRDFSgraph.add((ex.publishedBy, rdfs.range, ex.Publisher))\n",
    "myRDFSgraph.add((ex.hasTitle, rdfs.domain, ex.Videogame))\n",
    "myRDFSgraph.add((ex.hasTitle, rdfs.subPropertyOf, rdfs.Literal))\n",
    "myRDFSgraph.add((ex.availableOn, rdfs.range, ex.Platform))\n",
    "\n",
    "\n",
    "print(\"Now let's check what we can infer from your knowledge graph...\")\n",
    "print(\"The more rules you cover, the better!\")\n",
    "myRDFSreasoner(myRDFSgraph)\n",
    "serialize_graph(myRDFSgraph)\n",
    "\n",
    "save_graph(myRDFSgraph, 'myRDFSgraph.ttl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (20 points) Compare local inferences with GraphDB results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload *myRDFSgraph.ttl* to GraphDB (check [the GraphDB tutorial](https://github.com/ucds-vu/knowledge-data-vu/blob/master/Tutorials/Preliminaries/tutorial-GraphDB.md) before starting to work with GraphDB).\n",
    "\n",
    "Formulate two different SPARQL queries, and write a Python code that executes these queries over your GraphDB SPARQL endpoint (check example of Task 1).\n",
    "\n",
    "**Each SPARQL query should return a _different type_ of inferred knowledge** (at least one triple that was not explicitly asserted in the graph).\n",
    "\n",
    "Specify below next to your query (using a comment '# ...') which type of RDFS rule is the GraphDB reasoner using to infer this answer (rdfs2, rdfs3, rdfs5, rdfs7, rdfs9, rdfs11). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your GraphDB repository URL (setup -> repositories -> repository url) and assign it to the variable 'myEndpoint' below. \n",
    "# It should be similar to this: \n",
    "\n",
    "myEndpoint = \"http://127.0.0.1:7200/repositories/KnowledgeAndData\"  # KnowledgeAndData is the name of the repository\n",
    "#myEndpoint = \"http://Amund:7200/repositories/KnowledgeAndData\"\n",
    "sparql = SPARQLWrapper(myEndpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/kad/Platformer rdf:type http://example.com/kad/Genre\n",
      "http://example.com/kad/MOBA rdf:type http://example.com/kad/Genre\n"
     ]
    }
   ],
   "source": [
    "# Query 1 - Specify which RDFS rule are you testing: \n",
    "\n",
    "# Check example of Task 1 on how to query remote SPARQL endpoints\n",
    "\n",
    "# rdfs3\n",
    "sparql.setQuery(\"\"\"\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX ex: <http://example.com/kad/>\n",
    "\n",
    "SELECT ?Genre ?class\n",
    "WHERE {\n",
    "    SERVICE <http://Amund:7200/repositories/KnowledgeAndData> {\n",
    "        ?x rdfs:range ?class .\n",
    "        ?z ?x ?Genre . FILTER (?class = ex:Genre)\n",
    "    }\n",
    "}\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result[\"Genre\"][\"value\"], \"rdf:type\", result[\"class\"][\"value\"])  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/kad/RiotClient rdfs:subPropertyOf http://example.com/kad/Computer\n"
     ]
    }
   ],
   "source": [
    "# Query 2 - Specify which RDFS rule are you testing: \n",
    "\n",
    "# Check example of Task 1 on how to query remote SPARQL endpoints\n",
    "\n",
    "# rdfs 5\n",
    "sparql.setQuery(\"\"\"\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX ex: <http://example.com/kad/>\n",
    "\n",
    "SELECT ?platform ?class\n",
    "WHERE {\n",
    "\tSERVICE <http://Amund:7200/repositories/KnowledgeAndData> {\n",
    "  \t\t?platform rdfs:subPropertyOf ?x .\n",
    "        ?x rdfs:subPropertyOf ?class . FILTER (?class = ex:Computer)\n",
    "\t}\n",
    "}\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result[\"platform\"][\"value\"], \"rdfs:subPropertyOf\", result[\"class\"][\"value\"])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting the assignment\n",
    "\n",
    "Please submit this notebook (.ipynb) once you're finished with the assignment. It is not necessary to submit the created turtle files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
