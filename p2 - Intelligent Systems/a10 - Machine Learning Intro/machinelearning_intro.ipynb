{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Systems 2023: Practical Assignment 10\n",
    "\n",
    "## Machine Learning Introduction\n",
    "\n",
    "Your name: Amund Strøm\n",
    "\n",
    "Your VUnetID: ast101\n",
    "\n",
    "If you do not provide your name and VUnetID we will not accept your submission. \n",
    "\n",
    "### Preliminaries\n",
    "\n",
    "At the end of this exercise you should be able to work with some basic Machine Learning concepts, and implement and evaluate simple classifiers for *spam classification* using the popular machine learning library scikit-learn(https://scikit-learn.org/stable/).\n",
    "Scikit-learn offers a many helpful methods for creating simple machine learning models and to perform data science.\n",
    "\n",
    "In this assignment you will:\n",
    "1. Use pandas to read a dataset from a comma-separated-value (.csv) file.\n",
    "2. You should be able to create tf-idf feature vectors with scikit-learn.\n",
    "3. You should be able to create a simple classification and evaluate basic classification models.\n",
    "4. You should have learned to improve classification models for textual data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Practicalities\n",
    "\n",
    "Follow this Notebook step-by-step. For this course it is necessary that you manipulate the python programmes we provide. You can do the exercises in any Programming Editor of your liking. Still, please fill in the questions in this notebook as usual. \n",
    "\n",
    "Please use your studentID+Assignment10.ipynb as the name of the Notebook, and fill in the missing cells.   \n",
    "\n",
    "Note: unlike the courses dedicated to programming we will not evaluate the style of the programs. But we will, however, test your programs on other data that we provide, and your program should give the correct output to the test-data as well.\n",
    "\n",
    "As was mentioned, the assignment is graded as pass/fail. To pass you need to have either a full working code or an explanation of what you tried and what didn't work for the tasks that you were unable to complete (you can use multi-line comments or a text cell).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install some packages\n",
    "\n",
    "First we need to install some additional packages that we will use throughout this assignment.\n",
    "This might take a while.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training classification models with Sci-Kit Learn.\n",
    "\n",
    "With this notebbook, you have downloaded a small .csv file containing a public spam/ham SMS dataset that is often used for text classification purposes.\n",
    "We will load this dataset with the pandas library (https://pandas.pydata.org/), which is often used for data analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "import pandas as pd\n",
    "df = pd.read_csv ('spam.csv', encoding = \"ISO-8859-1\")\n",
    "df.dropna(how=\"any\", inplace=True, axis=1)\n",
    "df.columns = ['label', 'message']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the resulting pandas dataframe contains an index column, a label, and the message.\n",
    "Let's first have a look at the class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "For this first task, we ask you to do a basic data science task. Try to get an idea about the dataset by checking how balanced/unbalanced the dataset is. To do this, you need to compute the proportion of the *ham* and the *spam* class.\n",
    "\n",
    "Find a Pandas function to compute the frequency of the labels to get an idea of the label distribution. \n",
    "Then write a short description of your results.\n",
    "What percentage of the messages are labelled as spam?\n",
    "\n",
    "*Hint: Have a look at the Pandas documentation (https://pandas.pydata.org/docs/). There a many ways to get your answer!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "ham     86.593683\n",
      "spam    13.406317\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "freq = df['label'].value_counts()   # Get values\n",
    "freq = freq / len(df) * 100         # Convert to percentage\n",
    "print(freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyReport1 = \"\"\"\n",
    "Roughly 87'%' of the emails are labeled as ham, this means that 13'%' are labeled as spam\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snipped will create textual features, as discussed in last weeks lecture. We will create tf-idf vectors and will append them to our pandas dataframe.\n",
    "Then we will perform a simple train/test split of our dataset, using the scikit-learn splitting functions.\n",
    "\n",
    "Have a look at the different parts that we created. What do the dataframes X_train, y_train, X_test, y_test contain?\n",
    "Try to understand what is happening here by also having a look at the scikit-learn documentation (https://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#compute the tf-idf vectors for the messages and create a new dataframe for them\n",
    "v = TfidfVectorizer()\n",
    "tf_idf = v.fit_transform(df['message'])\n",
    "df_tfidf = pd.DataFrame(tf_idf.toarray(), columns=v.get_feature_names_out())\n",
    "\n",
    "#combine the original dataframe with the dataframe for the tf-idf vectors\n",
    "dataframes = [df, df_tfidf]\n",
    "df_new = pd.concat(dataframes, axis=1)\n",
    "\n",
    "#split the dataset into training and test set\n",
    "train, test = train_test_split(df_new, test_size=0.9)\n",
    "\n",
    "#separate feature matrices X from label vector y\n",
    "X_train = train.iloc[:, 3:]\n",
    "X_test = test.iloc[:, 3:]\n",
    "y_train = train['label']\n",
    "y_test = test['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>...</th>\n",
       "      <th>ó_</th>\n",
       "      <th>û_</th>\n",
       "      <th>û_thanks</th>\n",
       "      <th>ûªm</th>\n",
       "      <th>ûªt</th>\n",
       "      <th>ûªve</th>\n",
       "      <th>ûï</th>\n",
       "      <th>ûïharry</th>\n",
       "      <th>ûò</th>\n",
       "      <th>ûówell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3025</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4492</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>557 rows × 8671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      000  000pes  008704050406  0089  0121  01223585236  01223585334  \\\n",
       "3025  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "1072  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "711   0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "2089  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "4530  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "...   ...     ...           ...   ...   ...          ...          ...   \n",
       "991   0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "626   0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "2005  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "4492  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "885   0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "\n",
       "      0125698789   02  0207  ...   ó_   û_  û_thanks  ûªm  ûªt  ûªve   ûï  \\\n",
       "3025         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "1072         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "711          0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "2089         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "4530         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "...          ...  ...   ...  ...  ...  ...       ...  ...  ...   ...  ...   \n",
       "991          0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "626          0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "2005         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "4492         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "885          0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "\n",
       "      ûïharry   ûò  ûówell  \n",
       "3025      0.0  0.0     0.0  \n",
       "1072      0.0  0.0     0.0  \n",
       "711       0.0  0.0     0.0  \n",
       "2089      0.0  0.0     0.0  \n",
       "4530      0.0  0.0     0.0  \n",
       "...       ...  ...     ...  \n",
       "991       0.0  0.0     0.0  \n",
       "626       0.0  0.0     0.0  \n",
       "2005      0.0  0.0     0.0  \n",
       "4492      0.0  0.0     0.0  \n",
       "885       0.0  0.0     0.0  \n",
       "\n",
       "[557 rows x 8671 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's have a look at the different dataframes here\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification\n",
    "\n",
    "\n",
    "In the lecture, we have introduced the naive Bayes classification algorithm and have already computed various examples by hand. Here, we will use scikit-learn to train your first own classification model for spam classification.\n",
    "However, all examples from the lecture were using categorical features, while our tf-idf vectors here are real-valued features. \n",
    "Thus, the model used here will be slightly different than what we have seen in the lecture.\n",
    "\n",
    "\n",
    "\n",
    "### Task 2\n",
    "\n",
    "Use the training and test set created in the previous cell and train a Naive Bayes classifier using sci-kit learn.\n",
    "Please have a look at the documentation on how to use classification model using X_train and y_train as an input.\n",
    "Afterwards compute the accuracy of your classfier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Naive Bayes classifier is:  94.03788634097707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "cor = X_test.shape[0]\n",
    "miss = (y_test != y_pred).sum()\n",
    "acc = 100 - ((miss * 100) / cor)\n",
    "\n",
    "print(\"The accuracy of the Naive Bayes classifier is: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have seen, the accuracy of your Naive Bayes classifier should be over 85%.\n",
    "This seems to be a very good score, for a very simple classification model and simple tf-idf features.\n",
    "\n",
    "### Task 3\n",
    "\n",
    "Have a look at different evaluation metrics for your classifier and discuss the suitability of accuracy for the spam classification task.\n",
    "Have a look at the definition of accuracy and come up with another metric, which is better suited for our problem\n",
    "\n",
    "*Hint: Have a look at this documentation and try out different evaluation metrics: https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9403788634097707\n",
      "0.9398619833264199\n"
     ]
    }
   ],
   "source": [
    "#try out other evaluation metrics here  \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyReport2 = \"\"\"\n",
    "Accuracy is maybe not the best metric in our case since our dataset contains way more ham than spam, therefore it will preform well even if it guesses wrong on all the spam\n",
    "cases, since ham will just outweigh all the cases. Therefore it may be a better idea to look at the f1-score, which calculates the harmonic mean of precision and recall.\n",
    "Precision in this context represents the proportion of predicted spam messages that are actually spam, while recall represents the proportion of actual spam messages that are \n",
    "correctly predicted as spam.\n",
    "\n",
    "The idea is that the cases where it actually matters to get the prediction right (predicitng spam) will be valued more in the metric for the classifier.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Come up with any improvements for the classification model here.\n",
    "You can come up with a new method and/or different features to improve the classification.\n",
    "Can you beat the baseline Naive Bayes model?\n",
    "\n",
    "If you try out a different classification model, the training of the model might take a couple of seconds.\n",
    "\n",
    "Write at least 10 sentences describing your improvements and why these improvements are helping to improve the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9439982724859741\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyReport3 = \"\"\"\n",
    "When choosing a model classification you have to consider many factors about the data, such as its charactersitics and patterns. The classification model I have choosen is \n",
    "called the support vector model (SVM), and we can see that it is a minor imporvement (94.5%) from the Naive Bayes classifier (91.7%). By looking at the data we can see why SVM\n",
    "is an improvment.\n",
    "\n",
    "Naive Bayes assumes that the data is truly independent, this will simplify the model but may miss out on complex relationships between the data. In our case it will look at each\n",
    "word independet and without context, which is of course wrong as words are connected to eachother to create meaning. SVM will find the optimal hyperplane to seperate different\n",
    "classes, and are therefore capable to capture a bigger context between classes.\n",
    "\n",
    "Naive Bayes is also very receptive when dealing with imbalanced datasets, meaning it will get a bias toward the class with the majority of examples. Which in our case there are\n",
    "way more exampels of non-spam emails than there are spam emails. SVM is way more robust when dealing with this problem.\n",
    "\n",
    "SVM compare to Naive Bayes has way more hyperparamaters to tune, meaning you can tune SVM to fit the dataset much better. This may require alot of resources to find the perfect\n",
    "hyperparamaters. In my case I have only used the 'linear' hyperplane paramater, but through a lot of trial and error you could probably improve the model even more with using\n",
    "different hyperparamaters.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Task: Collect all the results\n",
    "\n",
    "Uncomment and run this cell (and all the cells above) to generate the text file that you have to hand in together with the notebook on canvas!\n",
    "\n",
    "### Please hand in only the text file which is generated by this method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportToText(*args):\n",
    "    with open(args[0], \"w\") as f:\n",
    "        for argument in args:\n",
    "            f.write(\"{}\\n\".format(argument))\n",
    "\n",
    "exportToText(\"assignment10.txt\", MyReport1, MyReport2, MyReport3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
